{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Datashader is designed to make it simple to work with even very large\n",
    "datasets. To get good performance, it is essential that each step in the\n",
    "overall processing pipeline be set up appropriately. Below we share some\n",
    "of our suggestions based on our own [benchmarking](https://github.com/holoviz/datashader/issues/313) and optimization\n",
    "experience, which should help you obtain suitable performance in your\n",
    "own work.\n",
    "\n",
    "## File formats\n",
    "\n",
    "Based on our [testing with various file formats](https://github.com/holoviz/datashader/issues/129), we recommend storing\n",
    "any large columnar datasets in the [Apache Parquet](https://parquet.apache.org/) format when\n",
    "possible, using the [fastparquet](https://github.com/dask/fastparquet) library with [Snappy](https://github.com/andrix/python-snappy) compression:\n",
    "\n",
    "```\n",
    ">>> import dask.dataframe as dd\n",
    ">>> dd.to_parquet(filename, df, compression=\"SNAPPY\")\n",
    "```\n",
    "\n",
    "If your data includes categorical values that take on a limited, fixed\n",
    "number of possible values (e.g. \"Male\", \"Female\"),\n",
    "Parquet's categorical columns use a more memory-efficient data representation and\n",
    "are optimized for common operations such as sorting and finding uniques.\n",
    "Before saving, just convert the column as follows:\n",
    "\n",
    "```\n",
    ">>> df[colname] = df[colname].astype('category')\n",
    "```\n",
    "\n",
    "By default, numerical datasets typically use 64-bit floats, but many\n",
    "applications do not require 64-bit precision when aggregating over a\n",
    "very large number of datapoints to show a distribution. Using 32-bit\n",
    "floats reduces storage and memory requirements in half, and also\n",
    "typically greatly speeds up computations because only half as much data\n",
    "needs to be accessed in memory. If applicable to your particular\n",
    "situation, just convert the data type before generating the file:\n",
    "\n",
    "```\n",
    ">>> df[colname] = df[colname].astype(numpy.float32)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data objects\n",
    "\n",
    "Datashader performance will vary significantly depending on the library and specific data object type used to represent the data in Python, because different libraries and data objects have very different abilities to use the available processing power and memory. Moreover, different libraries and objects are appropriate for different types of data, due to how they organize and store the data internally as well as the operations they provide for working with the data. The data objects currently supported by Datashader are:\n",
    "\n",
    "- [Pandas DataFrame](https://pandas.pydata.org): Basic columnar data support, typically lower performance than the other options where those are supported. Does not typically support multi-threaded operation that can make full use of your CPU's cores, and is generally limited to datasets that fit in your CPU's accessible memory. Does not support ragged arrays like polygons efficiently on its own.\n",
    "- [Dask DataFrame (using Pandas DataFrame internally)](https://dask.org): Multi-threaded support built on Pandas that can make full use of your CPU's cores, distributed support for using multiple CPUs in a cluster, HPC system or the cloud, and out-of-core support for datasets larger than memory. \n",
    "- [cuDF](https://github.com/rapidsai/cudf): DataFrame stored on and processed using an NVIDIA GPU (general-purpose graphics processing unit).\n",
    "- [Dask DataFrame (using cuDF DataFrame internally)](https://rapidsai.github.io/projects/cudf/en/0.10.0/10min.html): DataFrame following a Dask API but implemented on NVIDIA GPUs internally. Provides multi-GPU support for computation distributed across multiple NVIDIA GPUs on the same or different machines.\n",
    "- [SpatialPandas DataFrame](https://github.com/holoviz/spatialpandas): DataFrame based on Pandas extended to support efficient storage and computation on ragged arrays for polygons and variable-length lines and for spatially indexed points, typically using one core of one CPU.\n",
    "- [Dask (using SpatialPandas DataFrame internally)](https://github.com/holoviz/spatialpandas): DataFrame using Dask's API built on SpatialPandas DataFrames that are combined with Dask to support multi-core, distributed, and out-of-core processing.\n",
    "- [Xarray+NumPy](http://xarray.pydata.org): Multidimensional (not columnar or ragged) array operation built on NumPy arrays.\n",
    "- [Xarray+DaskArray](https://dask.org/): Dask-based multidimensional array processing built on Dask arrays, with support for distributed (multi-CPU) operation.\n",
    "- [Xarray+CuPy](https://cupy.chainer.org): Dask-based multidimensional array processing built on CuPy arrays, with storage and processing on an NVIDIA GPU.\n",
    "\n",
    "Datashader's current release supports these libraries for nearly all of the Canvas glyph types (points, lines, etc.) where they would apply. Supported combinations of glyph and data library are listed in this table, where the entries mean:\n",
    "\n",
    "- **Yes**: Supported\n",
    "- **No**: Not (yet) supported, but could be with sufficient development effort (feel free to contribute effort or funding!)\n",
    "- **-**: Not supported because that combination is not normally appropriate or useful (e.g. columnar data libraries do not currently provide efficient multidimensional array support)\n",
    "\n",
    "<style type=\"text/css\">.arbit .trary a { color: inherit; }.arbit .trary\n",
    ".sL{text-align:center;padding:2px 2px 2px 2px;background-color:#ffffff;font-weight:bold;width:60px}.arbit .trary\n",
    ".sG{text-align:center;padding:2px 2px 2px 2px;background-color:#ffffff;font-weight:bold;font-family:monospace}.arbit .trary\n",
    ".sY{text-align:center;padding:2px 2px 2px 2px;background-color:#b7e1cd;}.arbit .trary \n",
    ".sN{text-align:center;padding:2px 2px 2px 2px;background-color:#f4c7c3;}.arbit .trary\n",
    ".sM{text-align:center;padding:2px 2px 2px 2px;background-color:#fce8b2;}.arbit .trary\n",
    "</style>\n",
    "\n",
    "<div class=\"arbit\">\n",
    "<table class=\"trary\" cellspacing=\"0\" cellpadding=\"0\">\n",
    "<thead><tr>\n",
    "<th class=\"sL\">Glyph</th>\n",
    "<th class=\"sL\">PandasDF</th>\n",
    "<th class=\"sL\">DaskDF + PandasDF</th>\n",
    "<th class=\"sL\">cuDF</th>\n",
    "<th class=\"sL\">DaskDF + cuDF</th>\n",
    "<th class=\"sL\">SpatialPandasDF</th>\n",
    "<th class=\"sL\">Dask + SpatialPandasDF</th>\n",
    "<th class=\"sL\">Xarray + NumPy</th>\n",
    "<th class=\"sL\">Xarray + DaskArray</th>\n",
    "<th class=\"sL\">Xarray + CuPy</th>\n",
    "</tr></thead>\n",
    "<tbody>\n",
    "\n",
    "<tr>\n",
    "<td class=\"sG\">Canvas.points</td>\n",
    "<td class=\"sY\">Yes</td>\n",
    "<td class=\"sY\">Yes</td>\n",
    "<td class=\"sY\">Yes</td>\n",
    "<td class=\"sY\">Yes</td>\n",
    "<td class=\"sY\">Yes</td>\n",
    "<td class=\"sY\">Yes</td>\n",
    "<td class=\"sN\">No</td>\n",
    "<td class=\"sN\">No</td>\n",
    "<td class=\"sN\">No</td>\n",
    "</tr>\n",
    "\n",
    "<tr>\n",
    "<td class=\"sG\">Canvas.line</td>\n",
    "<td class=\"sY\">Yes</td>\n",
    "<td class=\"sY\">Yes</td>\n",
    "<td class=\"sY\">Yes</td>\n",
    "<td class=\"sY\">Yes</td>\n",
    "<td class=\"sY\">Yes</td>\n",
    "<td class=\"sY\">Yes</td>\n",
    "<td class=\"sN\">No</td>\n",
    "<td class=\"sN\">No</td>\n",
    "<td class=\"sN\">No</td>\n",
    "</tr>\n",
    "\n",
    "<tr>\n",
    "<td class=\"sG\">Canvas.area</td>\n",
    "<td class=\"sY\">Yes</td>\n",
    "<td class=\"sY\">Yes</td>\n",
    "<td class=\"sY\">Yes</td>\n",
    "<td class=\"sY\">Yes</td>\n",
    "<td class=\"sM\">-</td>\n",
    "<td class=\"sM\">-</td>\n",
    "<td class=\"sN\">No</td>\n",
    "<td class=\"sN\">No</td>\n",
    "<td class=\"sN\">No</td>\n",
    "</tr>\n",
    "\n",
    "<tr>\n",
    "<td class=\"sG\">Canvas.trimesh</td>\n",
    "<td class=\"sY\">Yes</td>\n",
    "<td class=\"sY\">Yes</td>\n",
    "<td class=\"sN\">No</td>\n",
    "<td class=\"sN\">No</td>\n",
    "<td class=\"sM\">-</td>\n",
    "<td class=\"sM\">-</td>\n",
    "<td class=\"sN\">No</td>\n",
    "<td class=\"sN\">No</td>\n",
    "<td class=\"sN\">No</td>\n",
    "</tr>\n",
    "\n",
    "<tr>\n",
    "<td class=\"sG\">Canvas.raster</td>\n",
    "<td class=\"sM\">-</td>\n",
    "<td class=\"sM\">-</td>\n",
    "<td class=\"sM\">-</td>\n",
    "<td class=\"sM\">-</td>\n",
    "<td class=\"sM\">-</td>\n",
    "<td class=\"sM\">-</td>\n",
    "<td class=\"sY\">Yes</td>\n",
    "<td class=\"sY\">Yes</td>\n",
    "<td class=\"sM\">No</td>\n",
    "</tr>\n",
    "\n",
    "<tr>\n",
    "<td class=\"sG\">Canvas.quadmesh</td>\n",
    "<td class=\"sM\">-</td>\n",
    "<td class=\"sM\">-</td>\n",
    "<td class=\"sM\">-</td>\n",
    "<td class=\"sM\">-</td>\n",
    "<td class=\"sM\">-</td>\n",
    "<td class=\"sM\">-</td>\n",
    "<td class=\"sY\">Yes</td>\n",
    "<td class=\"sM\">No</td>\n",
    "<td class=\"sY\">Yes</td>\n",
    "</tr>\n",
    "\n",
    "<tr>\n",
    "<td class=\"sG\">Canvas.polygons</td>\n",
    "<td class=\"sM\">-</td>\n",
    "<td class=\"sM\">-</td>\n",
    "<td class=\"sM\">-</td>\n",
    "<td class=\"sM\">-</td>\n",
    "<td class=\"sY\">Yes</td>\n",
    "<td class=\"sY\">Yes</td>\n",
    "<td class=\"sM\">-</td>\n",
    "<td class=\"sM\">-</td>\n",
    "<td class=\"sM\">-</td>\n",
    "</tr>\n",
    "\n",
    "</tbody></table></div>\n",
    "\n",
    "In general, all it takes to use the indicated data library for a particular glyph type is to instantiate a DataFrame (Pandas, Dask, cuPy, SpatialPandas) or DataArray/DataSet (Xarray), and then pass it to the appropriate `ds.Canvas` method call, as illustrated in the various examples in the user guide and topics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Dask efficiently\n",
    "\n",
    "Even on a single machine, a Dask DataFrame\n",
    "typically give higher performance than Pandas, because it\n",
    "makes good use of all available cores, and it also supports out-of-core\n",
    "operation for datasets larger than memory.\n",
    "\n",
    "Dasks works on chunks of the data at any one time, called partitions.\n",
    "With Dask on a single machine, a rule of thumb for the number of\n",
    "partitions to use is `multiprocessing.cpu_count()`, which allows Dask to\n",
    "use one thread per core for parallelizing computations.\n",
    "\n",
    "When the entire dataset fits into memory at once, you can (and should) persist the\n",
    "data as a Dask dataframe prior to passing it into datashader, to ensure\n",
    "that data only needs to be loaded once:\n",
    "\n",
    "```\n",
    ">>> from dask import dataframe as dd\n",
    ">>> import multiprocessing as mp\n",
    ">>> dask_df = dd.from_pandas(df, npartitions=mp.cpu_count())\n",
    ">>> dask_df.persist()\n",
    "...\n",
    ">>> cvs = datashader.Canvas(...)\n",
    ">>> agg = cvs.points(dask_df, ...)\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
